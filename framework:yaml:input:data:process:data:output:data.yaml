-
# File: dsl-engine-config.yaml
engine:
  name: dsl-pipeline-engine
  version: "1.0.0"
  description: >
    A generic, extensible DSL runner that
    - parses input–process–output pipelines,
    - schedules & triggers runs,
    - executes shell & plugin steps,
    - handles errors & notifications,
    - integrates with Kubernetes and observability stacks.

  capabilities:
    parser:
      # Hỗ trợ cú pháp cơ bản + loop/condition/macros/template
      syntax:
        - input-process-output
        - conditional: if-else
        - loops: for_each, parallel
        - macros: functions
        - templating: Jinja2

    executor:
      modes:
        - shell    # run: "..."
        - plugin   # uses: org/plugin@v1
      plugin_system:
        manifest_key: plugin.yaml
        pull_policy: IfNotPresent
        cache_local: true
        versioning: true

    scheduler:
      triggers:
        - cron        # theo schedule
        - webhook     # event HTTP
        - file_watch  # thay đổi file / bucket
        - queue_event # Kafka / RabbitMQ

    error_handling:
      default_strategy: retry
      strategies:
        - retry         # chạy lại N lần
        - skip_on_error # bỏ qua bước lỗi
        - fail_pipeline # dừng pipeline
        - rollback      # hồi phục trạng thái cũ
      max_retries: 3

    notifier:
      channels:
        - email
        - slack
        - webhook

    observability:
      logging: real_time   # in stdout/stderr
      metrics: prometheus  # expose /metrics
      tracing: jaeger      # distributed-tracing

    k8s_integration:
      crd_support: true     # làm base cho operator
      cronjob_support: true # deploy CronJob khi trigger.type=cron
      job_support: true     # deploy Job cho mỗi run

  interfaces:
    cli:
      description: Command-line interface for local / CI usage
      commands:
        - init          # khởi tạo project
        - validate      # kiểm tra cú pháp & schema
        - run           # chạy pipeline
        - lint          # static analysis
        - list-plugins  # liệt kê plugin đã cài

    api:
      rest:
        enabled: true
        port: 8080
        endpoints:
          - /pipelines
          - /runs
          - /plugins
      grpc:
        enabled: false
        port: 50051
-
version: "1.0"

# ────────────────────────────────────────────────────────────────────────────
# INPUT: định nghĩa dữ liệu, trigger, params, secrets…
# ────────────────────────────────────────────────────────────────────────────
input:
  format: yaml
  dataPath: s3://my-bucket/raw/users.csv

  # 1) Trigger: cron hoặc webhook/light‐event
  trigger:
    type: cron
    schedule: "0 * * * *"    # chạy mỗi giờ
    # type: webhook
    # event: git.push

  # 2) Parameters & Secrets
  params:
    env: prod
    retries: 3
  secrets:
    - aws_key
    - aws_secret

# ────────────────────────────────────────────────────────────────────────────
# PROCESS: viết hết mọi logic (loop, if, plugin, parallel…)
# ────────────────────────────────────────────────────────────────────────────
process:
  # 1) Bắt đầu với parse, clean, validate
  steps:
    - parse: csv
    - clean_null: {}            # có thể coi đây là 1 plugin built-in

    # 2) Loop / parallel: chạy song song qua 10 chunk
    - parallel:
        forks: 10
        for_each: chunk in "${data.chunks}"
        steps:
          - uses: my-org/transform@v2
            with:
              input: "{{ chunk.uri }}"
              output: "/tmp/out-{{ chunk.id }}.parquet"

    # 3) Conditional & retry
    - if:
        condition: "${.params.env == 'prod'}"
        then:
          - run: echo "Running in production"
        else:
          - run: echo "Running in dev/testing"

    - retry: "{{ .params.retries }}"
      step:
        - uses: my-org/schema-validator@latest
          with:
            file: "*.parquet"
            schema: s3://schemas/user-schema.json

    # 4) Custom script / container plugin
    - run: |
        echo "Merging all parquet files…"
        parquet-merge /tmp/*.parquet -o /tmp/final.parquet

    # 5) Notification on success
    - on_success:
        - uses: my-org/slack-notify@1.0
          with:
            channel: "#data-pipelines"
            message: "Pipeline {{ metadata.name }} finished ✅"

  # 6) Global error‐handling
  on_error:
    strategy: rollback      # hoặc retry/skip/fail
    max_retries: 2

# ────────────────────────────────────────────────────────────────────────────
# OUTPUT: nơi lưu kết quả, định dạng, notifications…
# ────────────────────────────────────────────────────────────────────────────
output:
  format: parquet
  destination: s3://my-bucket/processed/users-{{ date "YYYYMMDD_HH" }}.parquet

  # Thông báo chung khi xong – email/slack…
  notifications:
    - type: email
      to: team-data@myorg.io
      subject: "Data pipeline {{ metadata.name }} completed"
      body: |
        *Status:* {{ status }}
        *Output:* {{ output.destination }}
-
input:
  format: yaml
  data: true
process:
  method: data
  steps:
    - parse: yaml
    - validate: schema
    - transform: output
output:
  format: data
  result: true
-

